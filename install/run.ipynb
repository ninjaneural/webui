{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#@markdown **WebUI Version 설치한 버전에 맞게 선택해주세요**\n",
        "TagVersion = 'v1.7.0' #@param [\"v1.3.2\", \"v1.4.1\", \"v1.5.2\", \"v1.6.0\", \"v1.7.0\", \"v1.8.0\"]\n",
        "\n",
        "#@markdown **체크포인트(checkpoint) 다운로드 URL**\n",
        "Checkpoint_Url = '' #@param {type:\"string\"}\n",
        "#@markdown **체크포인트 저장 파일이름**\n",
        "Checkpoint_Filename = 'checkpoint.safetensors' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **ControlNet 기본 모델 다운로드**\n",
        "#@markdown > *openpose, lineart, softedge, depth, canny, tile, ip2p*  \n",
        "ControlNet = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **ControlNet 추가 모델 다운로드**\n",
        "#@markdown > *segment, inpaint, scribble, mlsd, normalbae, suffle*  \n",
        "ControlNet_Extra = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **IP-Adapter 모델 다운로드**\n",
        "CotnrolNet_IPAdapter = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **TemporalNet 모델 다운로드**\n",
        "#@markdown > *temporalnet*  \n",
        "ControlNet_TemporalNet = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **T2I Adapter 모델 다운로드**\n",
        "#@markdown > *style, color, sketch, zoedepth, recolor*  \n",
        "ControlNet_T2I = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **AnimateDiff 모델 다운로드**\n",
        "AnimateDiff = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **AnimateDiff 추가 모션 모델 (HumansMotion,3DMotion)**\n",
        "AnimateDiff_Extra = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **LCM-LoRa사용**\n",
        "LCMLora = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown -----\n",
        "#@markdown *터널링*\n",
        "\n",
        "#@markdown **Ngrok**\n",
        "Ngrok_Key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "Workspace = 'install'\n",
        "ControlNet_Model_Path = \"/content/controlnet_models\"\n",
        "AnimateDiff_Model_Path = \"/content/motion_models\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print('install...')\n",
        "with capture.capture_output() as cap:\n",
        "  !apt -y install -qq aria2\n",
        "  !pip install -q torch==2.1.0 torchvision==0.16.0 xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "  !pip install httpx==0.24.1\n",
        "  !pip install segment_anything\n",
        "  !pip install insightface\n",
        "\n",
        "!mkdir -p {ControlNet_Model_Path}\n",
        "!mkdir -p {AnimateDiff_Model_Path}\n",
        "\n",
        "%cd /content/drive/MyDrive/{Workspace}\n",
        "\n",
        "print('download...')\n",
        "with capture.capture_output() as cap:\n",
        "  if Checkpoint_Url:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{Checkpoint_Url}\" -d ./models/Stable-diffusion -o {Checkpoint_Filename}\n",
        "\n",
        "  if ControlNet:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_openpose_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_lineart_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_softedge_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11f1p_sd15_depth_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_canny_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11f1e_sd15_tile_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11e_sd15_ip2p_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/resolve/main/control_sd15_inpaint_depth_hand_fp16.safetensors -d {ControlNet_Model_Path} -o control_sd15_inpaint_depth_hand_fp16.safetensors\n",
        "\n",
        "  if ControlNet_Extra:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_seg_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15s2_lineart_anime_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_inpaint_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_scribble_fp16.safetensors\n",
        "\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_mlsd_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11p_sd15_normalbae_fp16.safetensors\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -d {ControlNet_Model_Path} -o control_v11e_sd15_shuffle_fp16.safetensors\n",
        "\n",
        "  if CotnrolNet_IPAdapter:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.bin -d {ControlNet_Model_Path} -o ip-adapter_sd15.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus_sd15.bin -d {ControlNet_Model_Path} -o ip-adapter-plus_sd15.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.bin -d {ControlNet_Model_Path} -o ip-adapter-plus-face_sd15.pth\n",
        "\n",
        "  if ControlNet_TemporalNet:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/CiaraRowles/TemporalNet/resolve/main/diff_control_sd15_temporalnet_fp16.safetensors -d {ControlNet_Model_Path} -o diff_control_sd15_temporalnet_fp16.safetensors\n",
        "\n",
        "  if ControlNet_T2I:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -d {ControlNet_Model_Path} -o t2iadapter_style_sd14v1.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -d {ControlNet_Model_Path} -o t2iadapter_color_sd14v1.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd15v2.pth -d {ControlNet_Model_Path} -o t2iadapter_sketch_sd15v2.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_zoedepth_sd15v1.pth -d .{ControlNet_Model_Path} -o t2iadapter_zoedepth_sd15v1.pth\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/ioclab_sd15_recolor.safetensors -d {ControlNet_Model_Path} -o ioclab_sd15_recolor.safetensors  \n",
        "\n",
        "  if AnimateDiff:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v14.ckpt -d {AnimateDiff_Model_Path} -o mm_sd_v14.ckpt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt -d {AnimateDiff_Model_Path} -o mm_sd_v15.ckpt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15_v2.ckpt -d {AnimateDiff_Model_Path} -o mm_sd_v15_v2.ckpt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/v3_sd15_mm.ckpt -d {AnimateDiff_Model_Path} -o v3_sd15_mm.ckpt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/CiaraRowles/TemporalDiff/resolve/main/temporaldiff-v1-animatediff.ckpt -d {AnimateDiff_Model_Path} -o temporaldiff-v1-animatediff.ckpt\n",
        "    !ln -s ./extensions/animatediff/model/mm_sd_v14.ckpt {AnimateDiff_Model_Path}/mm_sd_v14.ckpt\n",
        "    !ln -s ./extensions/animatediff/model/mm_sd_v15.ckpt {AnimateDiff_Model_Path}/mm_sd_v15.ckpt\n",
        "    !ln -s ./extensions/animatediff/model/mm_sd_v15_v2.ckpt {AnimateDiff_Model_Path}/mm_sd_v15_v2.ckpt\n",
        "    !ln -s ./extensions/animatediff/model/v3_sd15_mm.ckpt {AnimateDiff_Model_Path}/v3_sd15_mm.ckpt\n",
        "    !ln -s ./extensions/animatediff/model/temporaldiff-v1-animatediff.ckpt {AnimateDiff_Model_Path}/temporaldiff-v1-animatediff.ckpt\n",
        "\n",
        "  if AnimateDiff_Extra:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/174464 -d {AnimateDiff_Model_Path} -o improvedHumansMotion_refinedHumanMovement.ckpt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/178017 -d {AnimateDiff_Model_Path} -o improved3DMotion_improved3DV1.ckpt\n",
        "    !ln -s {AnimateDiff_Model_Path}/improvedHumansMotion_refinedHumanMovement.ckpt ./extensions/animatediff/model/improvedHumansMotion_refinedHumanMovement.ckpt\n",
        "    !ln -s {AnimateDiff_Model_Path}/improved3DMotion_improved3DV1.ckpt ./extensions/animatediff/model/improved3DMotion_improved3DV1.ckpt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/neuralninja22/colab/master/misc/direct/{TagVersion}/directui.py -O /content/drive/MyDrive/{Workspace}/directui.py\n",
        "if LCMLora:\n",
        "  !git clone https://github.com/neuralninja22/lcm-sampler ./extensions/lcm-sampler\n",
        "  !wget https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/resolve/main/pytorch_lora_weights.safetensors -O ./models/Lora/lcm-lora-sdv1-5.safetensors\n",
        "\n",
        "if Ngrok_Key:\n",
        "  !pip install pyngrok\n",
        "  from pyngrok import conf, ngrok\n",
        "  conf.get_default().auth_token = Ngrok_Key\n",
        "  conf.get_default().monitor_thread = False\n",
        "  ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
        "  if len(ssh_tunnels) == 0:\n",
        "      ssh_tunnel = ngrok.connect(7860)\n",
        "      print('address：'+ssh_tunnel.public_url)\n",
        "  else:\n",
        "      print('address：'+ssh_tunnels[0].public_url)\n",
        "\n",
        "  !python launch.py --xformers --no-half-vae --enable-insecure-extension-access --theme dark --controlnet-dir {ControlNet_Model_Path}\n",
        "else:\n",
        "  !python launch.py --share --xformers --no-half-vae --enable-insecure-extension-access --theme dark --controlnet-dir {ControlNet_Model_Path}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "32c23ec9c124fdbef417fa7c12f036622d7e14abb755fc2527a38410604ea1a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
